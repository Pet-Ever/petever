{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    " \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r breed_requirements.txt\n",
    "#!pip install tf_explain\n",
    "#!pip install --upgrade pandas\n",
    "#!pip install opencv-python\n",
    "#!pip install matplotlib\n",
    "#!pip install pillow\n",
    "#!pip install sklearn\n",
    "#!pip install keras==2.6.0\n",
    "#!pip install imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "#import gdown\n",
    "import time\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tf_explain.core.activations import ExtractActivations\n",
    "\n",
    "from tensorflow.keras.applications.xception import decode_predictions\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "from imgaug import augmenters as iaa\n",
    "print(\"Loaded all libraries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1339452577.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_1647/1339452577.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    git clone https://github.com/android/camera-samples.git\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "image_path = './input/Images'\n",
    "output_num = 4\n",
    "num_of_categories = 4\n",
    "image_size = 299\n",
    "batch_size = 16\n",
    "#epoch은 계산해서 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "ap=tarfile.open('./input.tar')\n",
    "ap.extractall('./input')\n",
    "ap.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap=tarfile.open('./annotation_.tar')\n",
    "ap.extractall('./input')\n",
    "ap.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_list = sorted(os.listdir(image_path))\n",
    "\n",
    "num_classes = len(breed_list)\n",
    "print(\"{} breeds\".format(num_classes))\n",
    "print(breed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a time counter function to test the algorythms performance \n",
    "_start_time = time.time()\n",
    "\n",
    "def process_time_starts():\n",
    "    global _start_time \n",
    "    _start_time = time.time()\n",
    "\n",
    "def time_elapsed():\n",
    "    t_sec = round(time.time() - _start_time)\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\n",
    "    (t_hour,t_min) = divmod(t_min,60) \n",
    "    print('The process took: {}hour:{}min:{}sec'.format(t_hour,t_min,t_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy from https://www.kaggle.com/gabrielloye/dogs-inception-pytorch-implementation\n",
    "# reduce the background noise\n",
    "\n",
    "os.mkdir('data')\n",
    "for breed in breed_list:\n",
    "    os.mkdir('data/' + breed)\n",
    "    print(breed)\n",
    "print('Created {} folders to store cropped images of the different breeds.'.format(len(os.listdir('data'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for breed in os.listdir('data'):\n",
    "    for file in os.listdir('./input/Annotation/{}'.format(breed)):\n",
    "        img = Image.open('./input/Images/{}/{}.jpg'.format(breed, file))\n",
    "        tree = ET.parse('./input/Annotation/{}/{}'.format(breed, file))\n",
    "        xmin = int(tree.getroot().findall('object')[0].find('bndbox').find('xmin').text)\n",
    "        xmax = int(tree.getroot().findall('object')[0].find('bndbox').find('xmax').text)\n",
    "        ymin = int(tree.getroot().findall('object')[0].find('bndbox').find('ymin').text)\n",
    "        ymax = int(tree.getroot().findall('object')[0].find('bndbox').find('ymax').text)\n",
    "        img = img.crop((xmin, ymin, xmax, ymax))\n",
    "        img = img.convert('RGB')\n",
    "        img = img.resize((image_size, image_size))\n",
    "        img.save('data/' + breed + '/' + file + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(331 + i) # showing 9 random images\n",
    "    breed = np.random.choice(breed_list) # random breed\n",
    "    dog = np.random.choice(os.listdir('./input/Annotation/' + breed)) # random image \n",
    "    img = Image.open('./input/Images/' + breed + '/' + dog + '.jpg') \n",
    "    tree = ET.parse('./input/Annotation/' + breed + '/' + dog) # init parser for file given\n",
    "    root = tree.getroot() # idk what's it but it's from documentation\n",
    "    objects = root.findall('object') # finding all dogs. An array\n",
    "    plt.imshow(img) # displays photo\n",
    "    for o in objects:\n",
    "        bndbox = o.find('bndbox') # reading border coordinates\n",
    "        xmin = int(bndbox.find('xmin').text)\n",
    "        ymin = int(bndbox.find('ymin').text)\n",
    "        xmax = int(bndbox.find('xmax').text)\n",
    "        ymax = int(bndbox.find('ymax').text)\n",
    "        plt.plot([xmin, xmax, xmax, xmin, xmin], [ymin, ymin, ymax, ymax, ymin]) # showing border\n",
    "        plt.text(xmin, ymin, o.find('name').text, bbox={'ec': None}) # printing breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(331 + i) # showing 9 random images\n",
    "    breed = np.random.choice(breed_list) # random breed\n",
    "    dog = np.random.choice(os.listdir('./input/Annotation/' + breed)) # random image \n",
    "    img = Image.open('./input/Images/' + breed + '/' + dog + '.jpg') \n",
    "    tree = ET.parse('./input/Annotation/' + breed + '/' + dog) # init parser for file given\n",
    "    root = tree.getroot() # idk what's it but it's from documentation\n",
    "    objects = root.findall('object') # finding all dogs. An array\n",
    "    plt.imshow(img) # displays photo\n",
    "    for o in objects:\n",
    "        bndbox = o.find('bndbox') # reading border coordinates\n",
    "        xmin = int(bndbox.find('xmin').text)\n",
    "        ymin = int(bndbox.find('ymin').text)\n",
    "        xmax = int(bndbox.find('xmax').text)\n",
    "        ymax = int(bndbox.find('ymax').text)\n",
    "        plt.plot([xmin, xmax, xmax, xmin, xmin], [ymin, ymin, ymax, ymax, ymin]) # showing border\n",
    "        plt.text(xmin, ymin, o.find('name').text, bbox={'ec': None}) # printing breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_maps = {}\n",
    "label_maps_rev = {}\n",
    "for i, v in enumerate(breed_list):\n",
    "    label_maps.update({v: i})\n",
    "    label_maps_rev.update({i : v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_and_labels():\n",
    "    paths = list()\n",
    "    labels = list()\n",
    "    targets = list()\n",
    "    for breed in breed_list:\n",
    "        base_name = \"./data/{}/\".format(breed)\n",
    "        for img_name in os.listdir(base_name):\n",
    "            paths.append(base_name + img_name)\n",
    "            labels.append(breed)\n",
    "            targets.append(label_maps[breed])\n",
    "    return paths, labels, targets\n",
    "\n",
    "paths, labels, targets = paths_and_labels()\n",
    "\n",
    "assert len(paths) == len(labels)\n",
    "assert len(paths) == len(targets)\n",
    "\n",
    "targets = np_utils.to_categorical(targets, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageGenerator(Sequence):\n",
    "    \n",
    "    def __init__(self, paths, targets, batch_size, shape, augment=False):\n",
    "        self.paths = paths\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.shape = shape\n",
    "        self.augment = augment\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.paths) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_paths = self.paths[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        x = np.zeros((len(batch_paths), self.shape[0], self.shape[1], self.shape[2]), dtype=np.float32)\n",
    "        y = np.zeros((self.batch_size, num_classes, 1))\n",
    "        for i, path in enumerate(batch_paths):\n",
    "            x[i] = self.__load_image(path)\n",
    "        y = self.targets[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        return x, y\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for item in (self[i] for i in range(len(self))):\n",
    "            yield item\n",
    "            \n",
    "    def __load_image(self, path):\n",
    "        image = cv2.imread(path)\n",
    "        image = preprocess_input(image)\n",
    "        if self.augment:\n",
    "            seq = iaa.Sequential([\n",
    "                iaa.OneOf([\n",
    "                    iaa.Fliplr(0.5),\n",
    "                    iaa.Flipud(0.5),\n",
    "                    iaa.Sometimes(0.5,\n",
    "                    \n",
    "                    ),\n",
    "                    iaa.Affine(\n",
    "                        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                        rotate=(-40, 40),\n",
    "                        shear=(-8, 8)\n",
    "                    )\n",
    "                ])\n",
    "            ], random_order=True)\n",
    "            image = seq.augment_image(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(paths, targets, test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=1)\n",
    "\n",
    "train_ds = ImageGenerator(x_train, y_train, batch_size=32, shape=(image_size, image_size,3), augment=True)\n",
    "val_ds = ImageGenerator(x_test, y_test, batch_size=32, shape=(image_size, image_size,3), augment=False)\n",
    "test_ds = ImageGenerator(x_test, y_test, batch_size=32, shape=(image_size, image_size,3), augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.xception.Xception(weights='imagenet',include_top=False, pooling='avg', input_shape=(299,299,3))#Summary of Xception Model\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "\n",
    "#pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dim = 5 * 5 * 2048\n",
    "\n",
    "my_model = Sequential(base_model)\n",
    "\n",
    "#my_model.add(Flatten())\n",
    "#my_model.add(Dropout(0.1)) # dropout added\n",
    "my_model.add(Dense(1032, activation='relu',input_dim=flat_dim))\n",
    "my_model.add(Dense(512, activation='relu'))\n",
    "#my_model.add(Dropout(0.1))\n",
    "my_model.add(Dense(256, activation='relu'))\n",
    "my_model.add(Dense(output_num, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "total_epoch = 20\n",
    "learning_rate_init = 0.00001\n",
    "###################\n",
    "\n",
    "def lr_scheduler(epoch):\n",
    "    epoch += 1\n",
    "   \n",
    "    if epoch == 1:\n",
    "        return learning_rate_init\n",
    "    \n",
    "    elif epoch >= 2 and epoch <= 40:\n",
    "        return (0.2*epoch**3)*math.exp(-0.45*epoch)*learning_rate_init\n",
    "    \n",
    "    else:\n",
    "        return lr_scheduler(40-1)\n",
    "    \n",
    "\n",
    "stage = [i for i in range(0,25)]\n",
    "learning_rate = [lr_scheduler(x) for x in stage]\n",
    "plt.plot(stage, learning_rate)\n",
    "print(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience = 6, mode='max', min_delta=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_time_starts()\n",
    "\n",
    "hist = my_model.fit_generator(generator=train_ds, steps_per_epoch=22, validation_data=val_ds,  validation_steps=7, epochs=20, callbacks=[scheduler])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, met in enumerate(['accuracy', 'loss']):\n",
    "    ax[i].plot(hist.history[met])\n",
    "    ax[i].plot(hist.history['val_' + met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.save('my_model.h5', overwrite=True) \n",
    "my_model.save_weights('dog_breed_xcept_weights.h5', overwrite=True)\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = my_model.evaluate_generator(generator=test_ds,steps=int(100))\n",
    "\n",
    "print(\"Test results \\n Loss:\",test_loss,'\\n Accuracy',test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_predict(url, filename):\n",
    "    # download and save\n",
    "    os.system(\"curl -s {} -o {}\".format(url, filename))\n",
    "    img = Image.open(filename)\n",
    "    img = img.convert('RGB')\n",
    "    img = img.resize((299, 299))\n",
    "    img.save(filename)\n",
    "    # show image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    # predict\n",
    "    img = image.imread(filename)\n",
    "    img = preprocess_input(img)\n",
    "    probs = my_model.predict(np.expand_dims(img, axis=0))\n",
    "    for idx in probs.argsort()[0][::-1][:5]:\n",
    "        print(\"{:.2f}%\".format(probs[0][idx]*100), \"\\t\", label_maps_rev[idx].split(\"-\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_and_predict(\"https://cdn.pixabay.com/photo/2018/08/12/02/52/belgian-mallinois-3599991_1280.jpg\", \"test_1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_and_predict(\"https://image-notepet.akamaized.net/seimage/20210701%2Ffecb3cba5e15e0c06c3342d3c532ed2c.jpg\", \"test_2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_and_predict(\"https://img.animalplanet.co.kr/news/2020/06/03/700/oh0m1i1id397rk523z3k.jpg\", \"test_3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(my_model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_model_file = pathlib.Path(\"Classification2.tflite\")\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ubuntu16.04-python3.7-cuda10.1-cudnn7.6-tensorflow2.3",
   "language": "python",
   "name": "ubuntu16.04-python3.7-cuda10.1-cudnn7.6-tensorflow2.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
